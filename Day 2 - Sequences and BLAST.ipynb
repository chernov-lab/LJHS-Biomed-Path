{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part C\n",
    "## Working with Sequence files using Biopython\n",
    "\n",
    "The code boxes below will increase in complexity as we go on. \n",
    "\n",
    "Comments in the code begin with #. Read these if you want help understanding the code.\n",
    "\n",
    "In the first code box below, the first line \"turns on\" the SeqIO function of Biopython, a package (set of tools) built for biology and biochemistry! You can learn more at https://biopython.org/\n",
    "\n",
    "The second line uses SeqIO (think: sequence input and output) to read a fasta file and stores the information as a list of records.\n",
    "\n",
    "***\n",
    "<font color=blue><b>STEP C1:</b></font> Lets work with a bigger set of data. This time we will analyze all reviewed entries for coronavirus \"Spike glycoprotein\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "platform.system()\n",
    "\n",
    "brew_folder = \"\" \n",
    "if platform.system() == 'Darwin':\n",
    "    brew_folder = \"/opt/homebrew/bin/\"\n",
    "    \n",
    "print (brew_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO # imports the SeqIO function from Biopython\n",
    "\n",
    "fasta_file = \"spike\"\n",
    "fasta_folder = \"big_data\"\n",
    "\n",
    "records = list(SeqIO.parse(fasta_folder + \"/\" + fasta_file + \".fasta\", \"fasta\"))     # reads the fasta file into a list of records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<font color=blue><b>STEP C2:</b></font> Next, how can we access different information about the sequence records stored in the file.\n",
    "***\n",
    "~~~Python\n",
    "print(\"File %s contains %d records\" % (fasta_file, len(records)))   # prints the number of sequences\n",
    "print(records[0]) #prints the information in the first record\n",
    "~~~\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"File %s contains %d records\" % (fasta_file, len(records)))   # prints the number of sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<font color=blue><b>STEP C3:</b></font>  Run the code below to print only the sequence of the first record.\n",
    "\n",
    "You should be able to see that first record includes several things: an ID, Name, Description, and a Sequence.\n",
    "\n",
    "We can access each of those items specifically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(records[0]) #prints the information in the first record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<font color=blue><b>STEP C4:</b></font>  Or print the complete sequence of the first record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(records[0].seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<font color=blue><b>STEP C5:</b></font> The next code box shows us how to list the first 10 ids. Then it lists the first record id and its sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The sequence record ids are:\\n\")\n",
    "for i in range(0, 10):                     # this creates a variable i and counts to 10\n",
    "    print(records[i].id)                          # prints the id for record i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Great! The code above finds the first 10 records (recall in Python we start counting at zero), so records[0].id gets the identification of the first record. \n",
    "\n",
    "<font color=blue><b>STEP C6:</b></font> We can also look at the last record id. You could put in the number of records (less one), but -1 is easier! The -1 starts counting from the end of the records list and you don't need to know how many records you have.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prints the record id and its sequence\n",
    "print(\"\\nThe record: %s has a sequence of: %s\\n\" % (records[-1].id, records[-1].seq))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue><b>STEP C7:</b></font> Before you move on, check your knowledge by using the empty code box above to enter some code to answer these questions.\n",
    "\n",
    "    1. What is the sequence id for the 3rd record?\n",
    "    2. What is the sequence id for the *penultimate* record?\n",
    "    3. What is the sequence id for the records from 50th to 69th?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prints the record id and its sequence\n",
    "print(\"\\nThe record: %s has a sequence of: %s\\n\" % (records[3].id, records[3].seq))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50,69):                     # this creates a variable i and counts\n",
    "    print(records[i].id)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<font color=blue><b>STEP C8:</b></font> It might be quite clear that simply locating records by their number isn't always the best way to interact with the data. Perhaps we would like to search by name, ID, or description. Let's examine the comments below to see how we can do this. You will need to edit the line that sets the variable search_term. In the code box below, change the text <b>\\<<<search term here\\>>></b> to one of the search terms below. Then run the code box.\n",
    "\n",
    "    Search term ideas: spike, coronavirus, acute, SARS\n",
    "\n",
    "    Where to search ideas: id, description, name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re  # imports the re (Regular Expressions) functions\n",
    "\n",
    "search_term = \"SARS\"   # in between the quotes we can add a search term.\n",
    "                                         \n",
    "counter = 0   # a variable to keep track of how many times we find the term\n",
    "\n",
    "for item in records:                       # this creates a loop to iterate over all the records               \n",
    "    if re.search(search_term, item.description, re.IGNORECASE):    # Here we use re.search to find the search term in the item ID, returns true if yes\n",
    "        print(item.description)                     # If the above is true we print the item ID...\n",
    "        counter = counter + 1              # and increment our counter\n",
    "    else: continue                         # if the search term wasn't found we do nothing, just continue on\n",
    "\n",
    "# the next two lines print a summary for us - either no hits or how many hits.\n",
    "        \n",
    "if not counter: print(\"We didn't find any results using the search term: %s\" % search_term)\n",
    "else: print(\"\\nWe found %i records using the search term: %s\" % (counter, search_term))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<font color=blue><b>STEP C9:</b></font> As you have seen above, the IDs are a little long and redundant with the name. The code below simplifies the record ID and writes a new, simpler file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_file = fasta_folder + \"/\" + fasta_file + \".fasta\"         # original file path\n",
    "simple_file = fasta_folder + \"/\" + fasta_file + \".simple.fasta\"   # new file path\n",
    "\n",
    "with open(original_file) as original, open(simple_file, 'w') as simple:  #opens the file to read and one to write\n",
    "    records = SeqIO.parse(original, 'fasta')   # here we use the Biopython SeqIO again to parse the file into records\n",
    "\n",
    "    for item in records:                       # iterate through each item in the list called records\n",
    "        tmp_name = str.split(item.id, \"|\")[1]      # sets the variable tmp_name to the second item generated by splitting at the | character \n",
    "        item.id = tmp_name                         # now this sets the id of that item to the name\n",
    "        SeqIO.write(item, simple, 'fasta')  # writes out the item information to the new, corrected fasta file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no output given for the above code. Let's consider how we changed this file by looking at the simplfied file.\n",
    "\n",
    "<font color=blue><b>STEP 11:</b></font> You can find the new file in the file browser in the left of your screen and double click to open it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Big Data Strategies - Filtering and Reducing Redundancy in Datasets\n",
    "\n",
    "Now that we have a simpler fasta file, we still have a lot of sequences to deal with. It is often best to use fast and easy methods to pare down a dataset before using more computationally intensive ones. \n",
    "\n",
    "We will start by filtering out small fragments and large proteins, then move on to removing redundancy.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering by length\n",
    "\n",
    "Let's visualize the distribution of sequence lengths in our dataset. The code below will generate a histogram of the lengths of sequences. Charlie Weiss will give a thorough demonstration of this tool on Thursday!\n",
    "\n",
    "<font color=blue><b>STEP 12:</b></font> Run the code below to generate a histogram of sequence lengths.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "records = list(SeqIO.parse(simple_file, \"fasta\"))\n",
    "\n",
    "lengths = []\n",
    "\n",
    "for i in records:\n",
    "    #print(i.seq)\n",
    "    lengths.append(len(i.seq))\n",
    "\n",
    "lengths.sort()\n",
    "#print(lengths)\n",
    "\n",
    "plt.hist(lengths, bins = 100)\n",
    "plt.xlabel('seq length')\n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue><b>STEP 13:</b></font> Answer the question:\n",
    "\n",
    "    1. Using the histogram, what are the most common lengths of proteins in this dataset?\n",
    "\n",
    "***\n",
    "\n",
    "   We will further reduce the complexity of this dataset by removing sequences that are much larger and much smaller than the most common lengths shown. Those variables can be determined using a histogram and easily changed for different datasets. Using the histogram we can identify values for the small_len=1000 and large_len=1600 variables.\n",
    "\n",
    "<font color=blue><b>STEP 14:</b></font>   Run the code below to remove short and long sequences and generate a new fasta file called \"files/uniprot-dtxr_simple_trim.fasta\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "original_file = simple_file\n",
    "trimmed_file = fasta_folder + \"/\" + fasta_file + \".simple.trim.fasta\"\n",
    "\n",
    "small_len = 1000\n",
    "large_len = 1600\n",
    "\n",
    "with open(original_file) as original, open(trimmed_file, 'w') as trimmed:\n",
    "    records = SeqIO.parse(original_file, 'fasta')\n",
    "\n",
    "    for record in records:\n",
    "        if len(record.seq) > small_len and len(record.seq) < large_len: \n",
    "            #print(len(record.seq))\n",
    "            SeqIO.write(record, trimmed, 'fasta')\n",
    "            \n",
    "records2 = list(SeqIO.parse(trimmed_file, \"fasta\"))\n",
    "print(\"We now have %i sequences in our fasta file.\" % len(records2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above procedure removed about 5,000 sequences. This is a good start, but still a lot of sequences to visualize.\n",
    "***\n",
    "## Reducing sequence redundancy using CD-HIT\n",
    "\n",
    "We will use the program CD-HIT to remove sequence within a given sequence similarity to another sequence. For example, the flag \"-c 0.4\" given below will keep only sequences with less than 40% sequence identity. The -n flag selects the word size used in processing. Less sequence identity requires the use of smaller words in comparing the sequences. From the CD-HIT manual:\n",
    "\n",
    "    Choice'of'word'size:\n",
    "        -n 5 for thresholds 0.7 ~ 1.0\n",
    "        -n 4 for thresholds 0.6 ~ 0.7\n",
    "        -n 3 for thresholds 0.5 ~ 0.6\n",
    "        -n 2 for thresholds 0.4 ~ 0.5\n",
    "\n",
    "CD-HIT was installed when you launched the Binder. This is one of the benefits of using Binder.org\n",
    "\n",
    "For this exercise we will use a cutoff of 40%. <b>In practice you might select higher values, but this will increase runtimes for the following steps and the visualization in the next Jupyter Notebook.</b>\n",
    "\n",
    "<font color=blue><b>STEP 15:</b></font> Let's run the code below. This runs CD-HIT using the simplified and trimmed fasta as input (-i) and creates a new fasta output (-o) named uniprot-dtxr_40.fasta that will be much smaller. The bang (!) at the beginning tells the notebook this is not a Python command, but rather a program to be run from the unix environment. <b>Note running CD-HIT takes a few minutes so this is a good time to take a quick break or ask questions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "hit_file = fasta_folder + \"/\" + fasta_file + \".40.fasta\"\n",
    "os.system(brew_folder + 'cd-hit -i ' + trimmed_file + ' -o ' + hit_file + ' -c 0.4 -n 2')\n",
    "\n",
    "#!cd-hit -i files/uniprot-dtxr_simple_trim.fasta -o files/uniprot-dtxr_40.fasta -c 0.4 -n 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CD-HIT has reduced over 30,000 sequences to under 2000 at 40% sequence identity! This is one strategy for dealing with very large datasets - they can be reduced. However, reduction needs to be done in a logical and reproducible manner. CD-HIT does just that. Again, depending on how closely related these proteins are, we might need to try different percent identity cutoffs. We will stay with 40%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msf_file = fasta_folder + \"/\" + fasta_file + \".40.msf\"\n",
    "print(hit_file)\n",
    "print(msf_file)\n",
    "os.system(brew_folder + \"clustalo -i \" + hit_file + \" --outfmt='msf' -o \" + msf_file + \" --force\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets inspect the MSF file to find the FURIN cleavage site\n",
    "<br><img src=\"images/furin_site.jpg\" width=800>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import AlignIO\n",
    "align = AlignIO.read(msf_file, \"msf\")\n",
    "print(align)\n",
    "\n",
    "# open and inspect the MSF file located in the files folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "align_partial = align[1:,1070:1100]\n",
    "print(align_partial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "### We will use a sequence LOGO plot to represent conservative amino acids in the multiple alignment\n",
    "\n",
    "In bioinformatics, a sequence LOGO is a graphical representation of the sequence conservation of nucleotides (in a strand of DNA/RNA) or amino acids (in protein sequences)\n",
    "\n",
    "A sequence LOGO consists of a stack of letters at each position. The relative sizes of the letters indicate their frequency in the sequences. \n",
    "\n",
    "First, we will test how the LOGO module works correctly by running a demo\n",
    "\n",
    "Run the code and tell if you can see the graph:\n",
    "***\n",
    "~~~Python\n",
    "import logomaker as lm\n",
    "lm.demo('fig1b')\n",
    "~~~\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logomaker as lm\n",
    "lm.demo('fig1b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Adding in sequences of known function\n",
    "\n",
    "We are almost done processing our FASTA dataset. In order to ensure that we can identify sequences of known function, we have created a small set of FASTA sequences of known function - obtained from the Protein Databank (https://rcsb.org). We will add these knowns to the FASTA file using the cat command (it stands for concatenate). \n",
    "\n",
    "<font color=blue><b>STEP 16:</b></font> Run the code below which combines the two files into a new file called \"files/final_40.fasta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<font color=blue><b>STEP B15:</b></font> To import our Multiple Alignment data into the LOGO module we \n",
    "\n",
    "First, we extract all amino acid sequences from the alignment and store them in a variable (AA):\n",
    "***\n",
    "~~~Python\n",
    "AA = []\n",
    "for record in align_partial:\n",
    "    AA.append(str(record.seq))\n",
    "AA\n",
    "~~~\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AA = []\n",
    "for record in align_partial:\n",
    "    AA.append(str(record.seq))\n",
    "AA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<font color=blue><b>STEP B16:</b></font> Next, we take AA variable and convert the alignment to a number matrix:\n",
    "***\n",
    "~~~Python\n",
    "counts_matrix = lm.alignment_to_matrix(AA, characters_to_ignore='-')\n",
    "counts_matrix\n",
    "~~~\n",
    "***\n",
    "After you run the code, inspect the number matrix and tell how these numbers relate to the amino acid sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_matrix = lm.alignment_to_matrix(AA, characters_to_ignore='-')\n",
    "counts_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<font color=blue><b>STEP B17:</b></font> Finally, let's print the sequence LOGO plot using the number matrix:\n",
    "***\n",
    "~~~Python\n",
    "lm.Logo(counts_matrix, \n",
    "        font_name='Stencil Std',\n",
    "        color_scheme='skylign_protein',\n",
    "        vpad=.2,\n",
    "        width=0.8)\n",
    "~~~\n",
    "***\n",
    "After you run the code, inspect the number matrix and tell how these numbers relate to the amino acid sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.Logo(counts_matrix, \n",
    "        font_name='Stencil Std',\n",
    "        color_scheme='skylign_protein',\n",
    "        vpad=.2,\n",
    "        width=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb_file = fasta_folder + \"/\" + fasta_file + \".pdb.fasta\"\n",
    "final_file = fasta_folder + \"/\" + fasta_file + \".final.fasta\"\n",
    "\n",
    "os.system('cat ' + hit_file + ' ' + pdb_file + ' > ' + final_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue><b>STEP 17:</b></font> Run the code below to determine the final number of sequences in your file! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = list(SeqIO.parse(final_file, \"fasta\"))    # use SeqIO to process the file\n",
    "\n",
    "print(\"There are %i sequences in your file.\\n\" % len(records))  # print the number of sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Making a BLAST-able database and performing an all-by-all BLAST search\n",
    "\n",
    "Now that we have our dataset we are going to use some of the NCBI BLAST tools to 1) create a searchable database using our processed set of sequences and 2) use protein BLAST to complete an all-by-all search of that database using each of those sequences.\n",
    "\n",
    "We will perform an analysis of the evolutionary links between these sequences by determining which sequences are most closely related to which others.\n",
    "\n",
    "<font color=blue><b>STEP 18:</b></font> Let's see what the command makeblastdb does by using the -h (help) flag after the program name. Go ahead and run the code below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !makeblastdb -help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output above tells us the application of the program and how to indicate input and outout files.\n",
    "\n",
    "<font color=blue><b>STEP 19:</b></font> In the code box below we have added input and output files and told the program it is a protein database. The input is the files/final_40.fasta file. We will name the output files files/finalpro_40. Go ahead and run this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalpro_file = fasta_folder + \"/\" + fasta_file + \".finalpro.fasta\"\n",
    "os.system(brew_folder + \"makeblastdb -in \" + final_file + \" -dbtype prot -out \" + finalpro_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That last step was really quite fast given the smaller number of sequences. You can try this with more sequences, it will be slower, but you might need to use more sequences to find connections among your proteins. We should be good with this number for the exercise today.\n",
    "\n",
    "<font color=blue><b>STEP 20:</b></font> Next we want to use blastp (Basic Local Alignment Search Tool - Protein) to take each of our protein sequences and search the database for connections. Let's start by finding out the usage of blastp by running the command below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !blastp -help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue><b>STEP 21:</b></font> <b>This is the final step in generating new data to visualize in the next Jupyter Notebook.</b> We will run the code below to use blastp to search the files/finalpro_40 database using each of the sequences in the files/final_40.fasta file. <b>To be very clear - this will run almost 2000 BLAST searches!!!</b>\n",
    "\n",
    "The outfmt controls the output formatting and the -evalue is the expectation value. Briefly evalues tell us how often we expect a search to return a given result by chance. An evalue of 1 would mean that the blast result would always be found by chance (and not by an evolutionary link). Smaller evalues help us to ensure that the results are not found simply by chance. In the code below we are using a value of 10e-40. Less stringent values of 10e-22 could also be used; however, this results in more data to visualize and longer processing times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(brew_folder + \"blastp -db \" + finalpro_file + \" -query \" + final_file + \" -outfmt \\\" 6 qseqid sseqid evalue\\\" -out \" + fasta_folder + \"/BLASTe40_out -num_threads 4 -evalue 10e-40\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the above code has completed running you should see a file in the file browswer at the left called \"BLASTe40_out\". This is simply a text file, but contains the information we want to visualize in the next Jupyter Notebook. <b>Let's download \"BLASTe40_out\" and \"final_40.fasta\" to our personal computers so we can use them later.<b> \n",
    "    \n",
    "<font color=blue><b>STEP 22:</b></font> Download the file by clicking on the file \"BLASTe40_out\" and then go up to the Jupyter file menu and Download. Repeat for \"final_40.fasta\" Please note where you are downloading these files on your computer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DistanceTreeConstructor\n",
    "The DistanceTreeConstructor has two algorithms: UPGMA (Unweighted Pair Group Method with Arithmetic Mean) and NJ (Neighbor Joining).\n",
    "\n",
    "Both algorithms construct trees based on a distance matrix. So before using these algorithms, let me introduce the DistanceCalculator to generate the distance matrix from a MultipleSeqAlignment object. The following code shows a common way to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Phylo\n",
    "from Bio.Phylo.TreeConstruction import DistanceCalculator\n",
    "calculator = DistanceCalculator('identity')\n",
    "\n",
    "distance_matrix = calculator.get_distance(align)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(distance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.Phylo.TreeConstruction import DistanceTreeConstructor\n",
    "constructor = DistanceTreeConstructor(calculator, 'nj')\n",
    "tree = constructor.build_tree(align)\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phylo_file = fasta_folder + \"/\" + fasta_file + \".tree.xml\"\n",
    "Phylo.write(tree, phylo_file, \"newick\") # newick  or phyloxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "fig = Phylo.draw(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
